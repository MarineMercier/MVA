{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ALTEGRAD_2021_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "# Transfer learning for NLP\n",
        "## ALTEGRAD - Lab session 3\n",
        "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
        "##### 23 November 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout=dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7eafc3-c7c4-45df-8ede-3196fb36f034"
      },
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec93dfae-8cd8-4a45-b639-de7c81024eb2"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-25 16:54:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.5’\n",
            "\n",
            "dict.txt.5          100%[===================>] 564.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-11-25 16:54:34 (36.0 MB/s) - ‘dict.txt.5’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287e8c28-bcc0-4e8c-81b7-d83063d8affa"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "#id = 4\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        #if word not in token2ind.keys():\n",
        "        token2ind[word] = idx + 4 #fill me\n",
        "            #id += 1\n",
        "\n",
        "ind2token = dict([(token2ind[k], k) for k in token2ind.keys()]) #fill me\n",
        "\n",
        "print(ind2token[1111])\n",
        "print(\"Size of vocabulary :\", len(token2ind.keys()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n",
            "Size of vocabulary : 50001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [self.token2ind[tok] if tok in self.token2ind.keys() else self.token2ind[\"<oov>\"] for tok in sequence]  #fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1,:,:]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "        #fill me step 4        \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(token2ind) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea30a9ee-591b-4053-8311-477384ea8431"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-25 16:54:42--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.5’\n",
            "\n",
            "\rpretraining_subset.   0%[                    ]       0  --.-KB/s               \rpretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-11-25 16:54:42 (166 MB/s) - ‘pretraining_subset.txt.5’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57903477-49a2-49c1-b7a6-d48bd3b59ec6"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me \"language_modeling\" or 'classification'\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.34323 | ppl 1545.692\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.51940 | ppl  678.171\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.25476 | ppl  520.486\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.08199 | ppl  437.901\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.98012 | ppl  395.487\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.87776 | ppl  357.008\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.55785 | ppl  259.266\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.52447 | ppl  250.754\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.49414 | ppl  243.261\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.45292 | ppl  233.438\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.43663 | ppl  229.668\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.40021 | ppl  221.454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c230df-28cd-4891-818b-43663d99aa88"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-25 16:54:55--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.5’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   229MB/s    in 0.4s    \n",
            "\n",
            "2021-11-25 16:54:55 (229 MB/s) - ‘pretrained_model_4layers.pt.5’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99599993-5ea2-4cd1-863b-a2d45c817293"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "--2021-11-25 16:54:58--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.5’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-11-25 16:54:58 (57.9 MB/s) - ‘sentencepiece.french.model.5’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(out[-1,:,:].squeeze()).item() #fill me\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    next_tokens = sent\n",
        "    while len(next_tokens) < max_len and next_tokens[-1]!= \"<eos>\":\n",
        "       next_token, _ = infer_next_token(next_tokens)\n",
        "       next_tokens += ' ' + ind2token[next_token]\n",
        "    return next_tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "560714c8-bb89-4259-ed9e-09fa758f0c2e"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les ▁gens ▁qui ▁ont ▁été ▁très ▁accueillants'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67e48fa-7068-4c15-f2e5-07fb38687c60"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-25 16:55:05--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.3’\n",
            "\n",
            "train.review.spm.3  100%[===================>]   1.43M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-11-25 16:55:05 (70.4 MB/s) - ‘train.review.spm.3’ saved [1495960/1495960]\n",
            "\n",
            "--2021-11-25 16:55:05--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.3’\n",
            "\n",
            "train.label.3       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-25 16:55:05 (53.4 MB/s) - ‘train.label.3’ saved [3200/3200]\n",
            "\n",
            "--2021-11-25 16:55:05--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.3’\n",
            "\n",
            "test.review.spm.3   100%[===================>]   1.78M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-11-25 16:55:06 (64.8 MB/s) - ‘test.review.spm.3’ saved [1864544/1864544]\n",
            "\n",
            "--2021-11-25 16:55:06--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.3’\n",
            "\n",
            "test.label.3        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-25 16:55:06 (69.2 MB/s) - ‘test.label.3’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    accuracy = []\n",
        "    for idx, batch in enumerate(data_loader):\n",
        "        x, y = batch \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        src_mask = model.base.generate_square_subsequent_mask(x.size(0)).to(device)\n",
        "        output = model(x, src_mask)[-1,:,:]\n",
        "        _, y_pred = torch.max(output, dim=1)\n",
        "        correct = y_pred.eq(y).sum().item()\n",
        "        acc = correct / x.size(0)\n",
        "        accuracy.append(acc)\n",
        "    return np.mean(accuracy)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfad421-390e-4ae1-b918-2bf5f8f5ecbb"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.77659 | ppl    2.174\n",
            "| epoch   1 |   100/  200 steps | loss 0.71094 | ppl    2.036\n",
            "| epoch   1 |   150/  200 steps | loss 0.77220 | ppl    2.165\n",
            "| epoch   2 |    50/  200 steps | loss 0.65878 | ppl    1.932\n",
            "| epoch   2 |   100/  200 steps | loss 0.64575 | ppl    1.907\n",
            "| epoch   2 |   150/  200 steps | loss 0.60748 | ppl    1.836\n",
            "| epoch   3 |    50/  200 steps | loss 0.39765 | ppl    1.488\n",
            "| epoch   3 |   100/  200 steps | loss 0.37962 | ppl    1.462\n",
            "| epoch   3 |   150/  200 steps | loss 0.30580 | ppl    1.358\n",
            "| epoch   4 |    50/  200 steps | loss 0.17029 | ppl    1.186\n",
            "| epoch   4 |   100/  200 steps | loss 0.10820 | ppl    1.114\n",
            "| epoch   4 |   150/  200 steps | loss 0.08014 | ppl    1.083\n",
            "| epoch   5 |    50/  200 steps | loss 0.01932 | ppl    1.020\n",
            "| epoch   5 |   100/  200 steps | loss 0.06074 | ppl    1.063\n",
            "| epoch   5 |   150/  200 steps | loss 0.02323 | ppl    1.024\n",
            "| epoch   6 |    50/  200 steps | loss 0.00018 | ppl    1.000\n",
            "| epoch   6 |   100/  200 steps | loss 0.00028 | ppl    1.000\n",
            "| epoch   6 |   150/  200 steps | loss 0.00587 | ppl    1.006\n",
            "| epoch   7 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.01987 | ppl    1.020\n",
            "| epoch   8 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.01164 | ppl    1.012\n",
            "| epoch   8 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00628 | ppl    1.006\n",
            "| epoch  14 |   100/  200 steps | loss 0.02255 | ppl    1.023\n",
            "| epoch  14 |   150/  200 steps | loss 0.02268 | ppl    1.023\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.05029 | ppl    1.052\n",
            "| epoch  15 |   150/  200 steps | loss 0.04256 | ppl    1.043\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.80090 | ppl    2.228\n",
            "| epoch   1 |   100/  200 steps | loss 0.69300 | ppl    2.000\n",
            "| epoch   1 |   150/  200 steps | loss 0.61684 | ppl    1.853\n",
            "| epoch   2 |    50/  200 steps | loss 0.47451 | ppl    1.607\n",
            "| epoch   2 |   100/  200 steps | loss 0.49133 | ppl    1.634\n",
            "| epoch   2 |   150/  200 steps | loss 0.42698 | ppl    1.533\n",
            "| epoch   3 |    50/  200 steps | loss 0.38881 | ppl    1.475\n",
            "| epoch   3 |   100/  200 steps | loss 0.37619 | ppl    1.457\n",
            "| epoch   3 |   150/  200 steps | loss 0.33393 | ppl    1.396\n",
            "| epoch   4 |    50/  200 steps | loss 0.22875 | ppl    1.257\n",
            "| epoch   4 |   100/  200 steps | loss 0.37419 | ppl    1.454\n",
            "| epoch   4 |   150/  200 steps | loss 0.36089 | ppl    1.435\n",
            "| epoch   5 |    50/  200 steps | loss 0.30188 | ppl    1.352\n",
            "| epoch   5 |   100/  200 steps | loss 0.20120 | ppl    1.223\n",
            "| epoch   5 |   150/  200 steps | loss 0.24377 | ppl    1.276\n",
            "| epoch   6 |    50/  200 steps | loss 0.15260 | ppl    1.165\n",
            "| epoch   6 |   100/  200 steps | loss 0.21338 | ppl    1.238\n",
            "| epoch   6 |   150/  200 steps | loss 0.18214 | ppl    1.200\n",
            "| epoch   7 |    50/  200 steps | loss 0.02766 | ppl    1.028\n",
            "| epoch   7 |   100/  200 steps | loss 0.07524 | ppl    1.078\n",
            "| epoch   7 |   150/  200 steps | loss 0.15656 | ppl    1.169\n",
            "| epoch   8 |    50/  200 steps | loss 0.02365 | ppl    1.024\n",
            "| epoch   8 |   100/  200 steps | loss 0.05402 | ppl    1.056\n",
            "| epoch   8 |   150/  200 steps | loss 0.03195 | ppl    1.032\n",
            "| epoch   9 |    50/  200 steps | loss 0.00663 | ppl    1.007\n",
            "| epoch   9 |   100/  200 steps | loss 0.00401 | ppl    1.004\n",
            "| epoch   9 |   150/  200 steps | loss 0.00367 | ppl    1.004\n",
            "| epoch  10 |    50/  200 steps | loss 0.00221 | ppl    1.002\n",
            "| epoch  10 |   100/  200 steps | loss 0.01084 | ppl    1.011\n",
            "| epoch  10 |   150/  200 steps | loss 0.00946 | ppl    1.010\n",
            "| epoch  11 |    50/  200 steps | loss 0.00105 | ppl    1.001\n",
            "| epoch  11 |   100/  200 steps | loss 0.00192 | ppl    1.002\n",
            "| epoch  11 |   150/  200 steps | loss 0.04443 | ppl    1.045\n",
            "| epoch  12 |    50/  200 steps | loss 0.02374 | ppl    1.024\n",
            "| epoch  12 |   100/  200 steps | loss 0.03162 | ppl    1.032\n",
            "| epoch  12 |   150/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00291 | ppl    1.003\n",
            "| epoch  13 |   100/  200 steps | loss 0.01219 | ppl    1.012\n",
            "| epoch  13 |   150/  200 steps | loss 0.00097 | ppl    1.001\n",
            "| epoch  14 |    50/  200 steps | loss 0.00054 | ppl    1.001\n",
            "| epoch  14 |   100/  200 steps | loss 0.00433 | ppl    1.004\n",
            "| epoch  14 |   150/  200 steps | loss 0.00054 | ppl    1.001\n",
            "| epoch  15 |    50/  200 steps | loss 0.00037 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.03685 | ppl    1.038\n",
            "| epoch  15 |   150/  200 steps | loss 0.00017 | ppl    1.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c7522462-bc5f-4e5a-9619-4c227eaaaa6c"
      },
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "space = np.linspace(0,epochs, epochs)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(space, from_scratch_valid_acc,label='Training from scratch')\n",
        "plt.plot(space, pretrained_valid_acc,label='Pretrained')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA5TC0ji9VQe"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVZdNwn81WhO",
        "outputId": "e69f25ee-5a84-447a-f784-421f6ef2fecd"
      },
      "source": [
        "#Classification\n",
        "model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "\n",
        "print(\"Model architecture\")\n",
        "print(model)\n",
        "sum_param = sum(p.numel() for p in model.base.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in the base model\", sum_param)\n",
        "\n",
        "sum_param = sum(p.numel() for p in model.classifier.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in classifier\", sum_param)\n",
        "\n",
        "sum_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in the model with classifier\", sum_param)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture\n",
            "Model(\n",
            "  (base): TransformerModel(\n",
            "    (encoder): Embedding(50001, 200)\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0, inplace=False)\n",
            "    )\n",
            "    (transformer_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): ClassificationHead(\n",
            "    (decoder): Linear(in_features=200, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters in the base model 10968200\n",
            "Number of trainable parameters in classifier 402\n",
            "Number of trainable parameters in the model with classifier 10968602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhXAO3rX-YHF",
        "outputId": "46e1baf2-3327-4ee5-ac59-071473f97407"
      },
      "source": [
        "# Language modeling \n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
        "\n",
        "print(\"Model architecture\")\n",
        "print(model)\n",
        "sum_param = sum(p.numel() for p in model.base.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in the base model\", sum_param)\n",
        "\n",
        "sum_param = sum(p.numel() for p in model.classifier.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in classifier\", sum_param)\n",
        "\n",
        "sum_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters in the model with classifier\", sum_param)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture\n",
            "Model(\n",
            "  (base): TransformerModel(\n",
            "    (encoder): Embedding(50001, 200)\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (transformer_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): ClassificationHead(\n",
            "    (decoder): Linear(in_features=200, out_features=50001, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters in the base model 10968200\n",
            "Number of trainable parameters in classifier 10050201\n",
            "Number of trainable parameters in the model with classifier 21018401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eby9P5VJFmPr",
        "outputId": "b47f801e-529e-4f3b-f0e0-6fa9bbeb6476"
      },
      "source": [
        "embedding = ntokens * nhid\n",
        "transformer_encoder = nlayers*nhid*((nhid+1)*(2+nhead*2)+4)\n",
        "total = embedding + transformer_encoder\n",
        "print('Total number of trainable parameters of the base model', total)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters of the base model 10968200\n"
          ]
        }
      ]
    }
  ]
}