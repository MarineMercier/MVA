{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACPNiuip-QVd"
   },
   "source": [
    "# Practical work on SAR synthesis\n",
    " \n",
    "### Florence TUPIN, Emanuele DALSASSO\n",
    "\n",
    "Images of the practical work can be found on: \n",
    "https://perso.telecom-paristech.fr/dalsasso/TPSAR/\n",
    "\n",
    "You have:\n",
    "- Terrasar-X images of metric resolution on Grand canyon in Colorado. \n",
    "- Terrasar-X image of Paris\n",
    "- ERS-1 image of Lausanne \n",
    "\n",
    "Some useful functions are available in the file *mvalab.py*.\n",
    "\n",
    "### Name: **WRITE YOUR NAME HERE**\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "To solve this practical session, answer the questions below. Then export the notebook with the answers using the menu option **File -> Download as -> Notebook (.ipynb)**. Then [submit the resulting file here](https://partage.imt.fr/index.php/s/Xj2A3MGLpcDZoxE) by next week.\n",
    "\n",
    "### Reading of images with TélécomParis format\n",
    "A useful function to read the images with Télécom-Paris format is *imz2mat*\n",
    "\n",
    "### First step: install needed packages \n",
    "In this and the following practical works, we are going to need\n",
    "- numpy: a fundamental package for scientific computing with Python\n",
    "- matplotlib: a Python 2D plotting library\n",
    "- scipy: library for numerical integration, interpolation, optimization, linear algebra and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPskUOLCVZ9h"
   },
   "source": [
    "## Introduction\n",
    "### Complex images \n",
    "SAR images are usually complex data. Here are some useful `numpy` functions: \n",
    "- to take the conjugate: `np.conj`\n",
    "- to take the absolute value: `np.abs`\n",
    "- to take the real part: `np.real` or `spy.real`\n",
    "- to take the imaginary part: `np.imag` or `spy.imag`\n",
    "- yo take the phase: `np.angle`. Value is between −π and +π.\n",
    "\n",
    "\n",
    "### Fourier transfrom of an image\n",
    "\n",
    "Python computes the Fourier transform of a 2D signal (matrix  Z) thanks to the package `np.fft`.\n",
    "- `np.fft.fft2` is the basic procedure. From a real image (2D array of real numbers), it returns a matrix of complex numbers.\n",
    "Be careful, the spectrum is given between 0 and 1 (in normalized frequency. To convert it between -0.5 and 0.5, you have to use `np.fft.fftshift` to center the spectrum.\n",
    "- `np.fft.ifft2` gives the 2D inverse Fourier transform.\n",
    "Be careful `np.fft.ifft2` usually gives a result with complex values even if the enter is a real matrix.\n",
    "- Do not forget that a spectrum is complex values. To visualize it,`np.abs` transforms a complex matrix to a real matrix.\n",
    "\n",
    "### Convolution\n",
    "- `np.convolve(vector, mask, mode='same')`: 1D convolution keeping the original vector size\n",
    "- `scipy.signal.convolve2d(image, mask, mode='same')`: 2D convolution keeping the orignal image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEwkUSWA-QVk"
   },
   "source": [
    "### Import the libraries and packages we are going to use\n",
    "The following cell imports all that is going to be necessary for the practical work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLGMPF6LdTOG"
   },
   "outputs": [],
   "source": [
    "!wget https://perso.telecom-paristech.fr/dalsasso/TPSAR/mvalab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SQWic4x-QVm"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy as spy\n",
    "import scipy.fftpack \n",
    "import scipy.signal\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import mvalab as mvalab\n",
    "from urllib.request import urlopen\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [9, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA-5vXjO-QVs"
   },
   "source": [
    "### SAR Images \n",
    "To read an image use {mvalab.imz2mat} with input parameter the image name (or url). \n",
    "It returns a list with a table of complex numbers, the number of columns and the number of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MZeANUZ-QVt"
   },
   "outputs": [],
   "source": [
    "url='https://perso.telecom-paristech.fr/dalsasso/TPSAR/imagesbase/'\n",
    "\n",
    "image_name='coloradoDP.CXF'\n",
    "data=mvalab.imz2mat(url+image_name)\n",
    "image_slc=data[0] # single-look complex image\n",
    "ncol=data[1] # number of columns\n",
    "nlin=data[2] # number of lines\n",
    "print(ncol)\n",
    "print(nlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUyYcTY7-QVx"
   },
   "source": [
    "### Visualizing SAR data \n",
    "Visualize the amplitude and phase of the complex backscattered electro-magnetic field\n",
    "on Grand Canyon image.\n",
    "When just using imshow the full dynamic of the image is linearly converted to [0,255].\n",
    "When using mvalab.visusar, a threshold is defined as follows:\n",
    "$$\n",
    "\\text{threshold} = \\mu+k\\times \\sigma\n",
    "$$ \n",
    "where $\\mu$ is the image mean and $\\sigma$ is the image standard deviation. This way, only values between 0 and the threshold are displayed (values above the threshold are saturated at 255).\n",
    "A usual value of k is 3 (default value).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H7tqvEs-QVx"
   },
   "outputs": [],
   "source": [
    "#visualization of amplitude data \n",
    "image_amplitude = # COMPLETE to compute the amplitude image\n",
    "plt.figure()\n",
    "plt.... # COMPLETE to visualize the amplitude image\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(image_amplitude.ravel(),density=True, bins='auto',range=[0., 500.])\n",
    "\n",
    "#mvalab.visusar uses a threshold th=mean+k*sigma to stretch the dynamic\n",
    "#two inpu parameters : table of pixels (absolute value) and k value to define the threshold\n",
    "k = ...# COMPLETE\n",
    "mvalab.visusar(...,k) # COMPLETE to visualize the amplitude image with threhsolding\n",
    "\n",
    "#visualization of phase data \n",
    "image_phase = # COMPLETE to compute the phase\n",
    "plt.figure()\n",
    "plt.imshow(image_phase+np.pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyriSO7OpStq"
   },
   "source": [
    "### Question 1.a\n",
    "Explain what you see in the different images of Colorado acquisition and the role of the $k$ value.\n",
    "Give an interpretation of the amplitude image (which areas do you recognize) \n",
    "and of the phase image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj3_24Frpgzn"
   },
   "source": [
    "### Answer 1.a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYgsn48p-QV1"
   },
   "source": [
    "## Part 1: Analysis of a SAR image \n",
    "In this part we will use an image of TerraSAR-X sensor (metric resolution) of Paris. \n",
    "Check that you recognize the main buildings on this image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gSU9xEv-QV2"
   },
   "outputs": [],
   "source": [
    "url='https://perso.telecom-paristech.fr/dalsasso/TPSAR/paris/'\n",
    "\n",
    "image_name='Eiffel.CXF'\n",
    "data_paris=mvalab.imz2mat(url+image_name)\n",
    "ncol=data_paris[1]\n",
    "nlin=data_paris[2]\n",
    "\n",
    "image_slc_paris = data_paris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrZ9BoEz-QV6"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [9, 9]\n",
    "image_amplitude_paris = np.abs(image_slc_paris)\n",
    "image_phase_paris = np.angle(image_slc_paris)\n",
    "mvalab.visusar(image_amplitude_paris)\n",
    "mvalab.visusar(image_phase_paris+math.pi,0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxSPO_mmqEqW"
   },
   "source": [
    "### Analysis of a subpart of the image \n",
    "Choose a sub-part of the image and visualize the amplitude image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpal1A3tp5tn"
   },
   "outputs": [],
   "source": [
    "image_crop_paris = # COMPLETE to crop the amplitude image\n",
    "mvalab.visusar(image_crop_paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccRgl-xMqNIt"
   },
   "source": [
    "### Question 1.b\n",
    "\n",
    "Explain where is the sensor relatively to the scene.\n",
    "\n",
    "Explain the appearence of the following buildings in the amplitude image : Eiffel Tower, Maison de la radio, Pont de Bir-Hakeim (you can use a [satellite optic image on googlemaps](https://www.google.com/maps/place/Eiffel+Tower/@48.851143,2.2797819,447m/data=!3m1!1e3!4m5!3m4!1s0x47e66e2964e34e2d:0x8ddca9ee380ef7e0!8m2!3d48.8583701!4d2.2944813) to help you).\n",
    "\n",
    "Explain the appearence of water and vegetated areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ciDf1wzqOZt"
   },
   "source": [
    "### Answer 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjsZGJfZ-QV9"
   },
   "source": [
    "### Spectral analysis \n",
    "Plot the modulus of complex spectrum of the image and the modulus of the Fourier transform of the image taken in amplitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZZNqgPF-QV-"
   },
   "outputs": [],
   "source": [
    "# SPECTRAL ANALYSIS mvalab.visusarspectre: plot the image and its Fourier spectrum\n",
    "mvalab.visusarspectre(...) # COMPLETE to visualize the complex spectrum \n",
    "mvalab.visusarspectre(...) # COMPLETE to visualize the image spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRbDtNwUrbBn"
   },
   "source": [
    "### Question 1.c\n",
    "\n",
    "Explain what you see in the Fourier spectrum of the complex image. How are the two axis related to the SAR image synthesis ?\n",
    "\n",
    "Explain what you see in the Fourier spectrum of the amplitude image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSOIpCL6Hx_-"
   },
   "source": [
    "### Answer 1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o57Jr9VM-QWT"
   },
   "source": [
    "## Part 2: SAR synthesis using SAR RAW data \n",
    "To study the SAR synthesis we will use a ERS-1 SAR image which is provided by ESA in \"raw\" format. \n",
    "It means that it corresponds to the image before the chirp compression in range and before the synthetic aperture in the azimuth direction. \n",
    "What do you see on the raw data ? Can you recognize the area ? (It corresponds to [Leman Lake and Lausanne](https://www.google.com/maps/place/Lausanne,+Switzerland/@46.5284586,6.5824552,12z/data=!3m1!4b1!4m5!3m4!1s0x478c293ecd89a7e5:0xeb173fc9cae2ee5e!8m2!3d46.5196535!4d6.6322734))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ida_AxB-QWU"
   },
   "outputs": [],
   "source": [
    "url='https://perso.telecom-paristech.fr/dalsasso/TPSAR/imagesbase/'\n",
    "\n",
    "image_name='lausanneED.CXF'\n",
    "\n",
    "data=mvalab.imz2mat(url+image_name)\n",
    "ncol=data[1]\n",
    "nlin=data[2]\n",
    "\n",
    "image_slc = data[0]\n",
    "image_amplitude = ... # COMPLETE\n",
    "image_phase = ... # COMPLETE\n",
    "\n",
    "# display amplitude\n",
    "mvalab.visusar(image_amplitude)\n",
    "\n",
    "# display phase\n",
    "mvalab.visusar(image_phase+math.pi,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-ratUDe-QWX"
   },
   "outputs": [],
   "source": [
    "# Fourier spectrum\n",
    "mvalab.visusarspectre(image_slc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMvgKU_tsfpD"
   },
   "source": [
    "### Question 2.a\n",
    "Where is the lake on this image ? How can we localize Lausanne city ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sau-YGkCsh9w"
   },
   "source": [
    "### Answer 2.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXMB9QuT-QWb"
   },
   "source": [
    "### Range compression (fast time)\n",
    "The raw data need to be compressed along the range direction using a matched filter. \n",
    "The chirp is given and corresponds to the emitted wave of ERS sensor. The matched filter is a temporal convolution \n",
    "or equivalently a multiplication of the Fourier transforms. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZO7GxRGU-QWc"
   },
   "outputs": [],
   "source": [
    "sigchirp=mvalab.chirp_ers()   #Warning only 703 points to encode the chirp\n",
    "nsig=np.size(sigchirp) # number of points\n",
    "K=4.1889e+11\n",
    "\n",
    "#display of the chirp (real and imaginary parts)\n",
    "plt.rcParams['figure.figsize'] = [6, 6]\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(np.real(sigchirp))\n",
    "plt.subplot(212)\n",
    "plt.plot(np.imag(sigchirp))\n",
    "plt.show()\n",
    "\n",
    "# display of the Fouriertransform of the chirp\n",
    "##%%%\n",
    "line_chirp=np.zeros(ncol,dtype=complex)\n",
    "line_chirp[0:nsig]=sigchirp # padding\n",
    "tfchirp=np.fft.fft(line_chirp)\n",
    "plt.figure()\n",
    "plt.plot(np.abs(np.fft.fftshift(tfchirp))) # center the chirp on 0[Hz]\n",
    "plt.show()\n",
    "\n",
    "# range compression done in the Fourier transform line by line by FT multiplication\n",
    "#to be completed \n",
    "fft1imagearray=np.fft.fft(image_slc,axis=1) # 1-D Fourier transform\n",
    "fft2imagearray=np.zeros((nlin,ncol),dtype=complex)\n",
    "for iut in range(nlin):\n",
    "    fft2imagearray[iut,:]=... # COMPLETE to apply chirp compression\n",
    "\n",
    "newimage=np.fft.ifft(fft2imagearray,axis=1)\n",
    "mvalab.visusarspectre(newimage,u'Chirp compression step')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l203X-IwnTV"
   },
   "source": [
    "### Question 2.b\n",
    "What is the effect of the chirp convolution in the range direction ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J-q8agOwpc1"
   },
   "source": [
    "### Answer 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plLO8TX2-QWh"
   },
   "source": [
    "### Azimuth compression (slow time) - approximation\n",
    "We are now interested in the synthetic aperture computation in the azimuth direction. Two different compression techniques will be analysed in the following cells.\n",
    "First, the synthesis is done very approximately by just adding the complex signals in column (azimuth) without doing the phase correction. \n",
    "Compute a simple column convolution with a chosen size (30, 50 70 pixels for instance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voFSFxH9-QWi"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##############  SYNTHESIS\n",
    "############## constant kernel\n",
    "## \n",
    "\n",
    "#choose the window width to do the azimuth processing \n",
    "width=... # COMPLETE\n",
    "#create a mask of values 1 with np.ones()\n",
    "mask=... # COMPLETE\n",
    "newimage_step1=np.zeros( (nlin,ncol),dtype=complex)\n",
    "#do the convolution with the mask in azimuth direction - to keep the same size use mode='same'\n",
    "for jut in range(ncol):\n",
    "    newimage_step1[:,jut] = ...# COMPLETE\n",
    "mytitle=u'Size of the uniform kernel : %d'%width\n",
    "mvalab.visusarspectre(...,mytitle) # COMPLETE to visualize the synthetized image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob0uBCIzwvKG"
   },
   "source": [
    "### Question 2.c\n",
    "\n",
    "What is the effect of the constant kernel convolution in the range direction ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSxuwW36wyod"
   },
   "source": [
    "### Answer 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W080Ob7m-QWk"
   },
   "source": [
    "### Azimuth compression (slow time) - synthetic aperture \n",
    "In this part, we will perform the real aperture synthesis. \n",
    "To do so, we will first compute the distance $R(y)$ from the sensor to each pixel considered along the azimuth direction denoted by $y$. This distance is given by:\n",
    "$$\n",
    "R(y) = R_0+\\frac{y^2}{2R_0}\n",
    "$$\n",
    "where $R_0=R(y=0)$ corresponds to the point of closest approach (PCA). This distance is then converted in a per-pixel phase shift $\\phi(y)$:\n",
    "$$ \n",
    "\\phi(y)=\\frac{4\\pi R(y)}{\\lambda}=\\frac{2\\pi y^2}{\\lambda R_0}+\\text{cst}\n",
    "$$\n",
    "\n",
    "The instantaneous frequency can be derived as follows:\n",
    "$$\n",
    "f(y)=\\frac{1}{2\\pi}\\frac{d\\phi(y)}{dy}=\\frac{2}{\\lambda}\\frac{dR(y)}{dy}=\\frac{2y}{\\lambda R_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E47J5QCL-QWl"
   },
   "outputs": [],
   "source": [
    "\n",
    "##############  SYNTHESIS\n",
    "##############  Modulated window\n",
    "#%%%\n",
    "#  We use a fixed length for the synthesis (=fixed number of samples - no range migration correction)\n",
    "lambda_wave = 3./53. # [cm]\n",
    "prf=1679.902 #theoretical PRF of ERS-1 (PRF = Pulse Repetition Frequency)\n",
    "satellite_speed=7460 # [m/s]\n",
    "\n",
    "# dsatel: distance from the sensor to the Earth for an incidence angle of 24 degrees (considered as constant in the swath here) \n",
    "# It corresponds to PCA = Point of Closest Approach\n",
    "dsatel=845000\n",
    "\n",
    "# convert the sampling rate into the distance along the flight direction between samples \n",
    "# deltay is the distance along the azimuth between subsequent pulses \n",
    "deltay=satellite_speed/prf\n",
    "\n",
    "#chosen number of points for the synthetic aperture synthesis \n",
    "window_size=800\n",
    "NN=int(0.5*window_size) # goes from -NN to +NN, i.e. from -400 to 400\n",
    "\n",
    "# computation of the phase ramp and complex exponential \n",
    "# replacing the \"natural window\" with weight 1\n",
    "\n",
    "# convert the number of samples into a distance measured in [m]\n",
    "# knowing that the distance between two samples is defined as deltay\n",
    "# vector_positions corresponds to y\n",
    "vector_positions = deltay*np.linspace(-NN,NN,window_size) #returns 800 evenly spaced points between -400 and 400\n",
    "\n",
    "# vector_pca contains a vector of the pca distances\n",
    "vector_pca=dsatel*np.ones(window_size)\n",
    "\n",
    "# For each sample, compute the distance between the sensor and the target\n",
    "# vector_R corresponds to R(y) \n",
    "vector_R=... # COMPLETE using Pythagoras' theorem\n",
    "\n",
    "# compute in vector_R_diff the difference between vector_R and vector_pca corresponding to the distance difference w.r.t. R(0)\n",
    "vector_R_diff = ... # COMPLETE\n",
    "\n",
    "# check you obtain a quadratic contribution \n",
    "plt.figure()\n",
    "plt.plot(vector_R_diff)\n",
    "plt.show()\n",
    "\n",
    "# convert the distance to the sensor in a phase contribution using phi=(4piR)/lambda\n",
    "# a factor 2 for return trip (two ways)\n",
    "vector_phi = ... # COMPLETE       \n",
    "\n",
    "#convert the phase in the complex exponential contribution (phase ramp)\n",
    "vector_ramp = ... # COMPLETE\n",
    "\n",
    "# check the instant frequency is linear: f = 1/(2pi)*d(phi)\n",
    "fd = 2/lambda_wave*np.diff(vector_R) #instant frequency, equal to fd = 1/(2*np.pi)*np.diff(vector_phi)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(np.real(vector_ramp))\n",
    "plt.subplot(312)\n",
    "plt.plot(np.imag(vector_ramp))\n",
    "plt.subplot(313)\n",
    "plt.plot(fd)\n",
    "plt.show()\n",
    "\n",
    "######################### Warning : use the image newimage after chirp compression in distance\n",
    "\n",
    "newimage_foc=np.zeros( (nlin,ncol),dtype=complex)\n",
    "#do the matched filter by azimuth convolution with mode='same'\n",
    "for jut in range(ncol):\n",
    "    newimage_foc[:,jut]=... # COMPLETE\n",
    "\n",
    "#display the synthetized image\n",
    "mytitle=u'Number of samples used to do the synthetic aperture : %d'%window_size\n",
    "mvalab.visusarspectre(..., mytitle) # COMPLETE\n",
    "#display the image after azimuth synthesis using a square window (previous question)\n",
    "mvalab.visusarspectre(...)\n",
    "#disaply the original image \n",
    "mvalab.visusarspectre(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f9Gnd6pxf-v"
   },
   "source": [
    "### Question 2.d\n",
    "Compare the synthesized image with the mean kernel and the one taking into account the phase variation due to the distance. Compare the image obtained after synthesis in range and azimuth direction and the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp0IFc_exiDV"
   },
   "source": [
    "### Answer 2.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yspMzPnD-QWq"
   },
   "source": [
    "### Azimuth multi_looking\n",
    "The size of the SLC pixel for ERS-1 are 3m in azimuth and 12m in range. \n",
    "To obtain square pixels, a simple processing is averaging amplitude values \n",
    "and then do an undersampling with a factor of 4. \n",
    "It is even better to do the averaging on intensity values (square of the modulus) \n",
    "and then take the square root. \n",
    "Do you recognize Lausanne on this image ? (use google maps to have an optical view). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raX4wXGF-QWs"
   },
   "outputs": [],
   "source": [
    "#define a vertical mask to do the convolution\n",
    "mask_vertical = ... # COMPLETE\n",
    "\n",
    "#do the convolution on the intensity image obtained by z.z* (=|z|²)\n",
    "#you will get the multi-looked image in intensity ml_int\n",
    "ml_int = ... # COMPLETE\n",
    "\n",
    "#do the sub-sampling to obtain square pixels with improved radiometry\n",
    "ml_int_sub = ... # COMPLETE\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 4]\n",
    "#take the square root of the intensity to have an amplitude image (proportional to |z|)\n",
    "mvalab.visusar(np.sqrt(ml_int_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKE0EEe_xre4"
   },
   "source": [
    "### Question 2.e\n",
    "What is the effect of multi-looking ? Is this image well oriented compared to a map ? Use the Lac de Bret to check this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFKUQpjJxufR"
   },
   "source": [
    "### Answer 2.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7eam4lm-QWv"
   },
   "source": [
    "## Example of a High Resolution image \n",
    "The obtained image after chirp compression and synthetic aperture processing is still difficult to understand because of the coarse resolution of ERS. \n",
    "To illustrate these processing on a more impressive case, you can apply the following functions. Basically it is the same as before, but with dedicated chirp and distance computations. \n",
    "WARNING: the range and azimuth are not the usual one (vertical = range direction, horizontal = azimuth direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeYPdUNj-QW4"
   },
   "outputs": [],
   "source": [
    "#example on the aerial image \n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "gdd.download_file_from_google_drive(file_id='1vR2m7Lb2aI6Dhak4u9eR2ZPGYhasmCO5',\n",
    "                                    dest_path='./HighRes.zip',\n",
    "                                    unzip=True)\n",
    "import sys\n",
    "sys.path.append('./HighRes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShZvCN54VZ9y"
   },
   "outputs": [],
   "source": [
    "# mvalab.synthese_range reads the matrix containing the raw data and the system \n",
    "#parameters and compute the synthesis in the range direction\n",
    "raw_data, range_compressed_data = mvalab.synthese_range('./HighRes/data2.mat')\n",
    "mvalab.visusar(raw_data) \n",
    "mvalab.visusar(range_compressed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6X4xPs9aVZ9z"
   },
   "outputs": [],
   "source": [
    "#mvalab.synthese_azimuth takes the range compressed image and does the azimuth compression step\n",
    "compressed_data = mvalab.synthese_azimuth(range_compressed_data, './HighRes/data2.mat')\n",
    "mvalab.visusar(compressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6XJtwFN-QW7"
   },
   "source": [
    "## (Bonus) Part 3: Sub aperture analysis\n",
    "Let us go back to the understanding of the complex spectrum information. \n",
    "Indeed, both axes of the complex Fourier transform of a Single look Complex image are related to SAR synthesis: the range (horizontal) axis is related to the chirp frequencies, and the azimuth (vertical) axis is related to the sensor positions during the Synthetic Aperture synthesis. \n",
    "The target is observed by the radar for a time corresponding to the observation time. Therefore, each frequency carries information about the observed target. We can see this in the following example, where we are going to consider only a sub part of the synthetic aperture of the radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EhYfx1QAiaj"
   },
   "source": [
    "### Sub-aperture on TerraSAR-X image of Paris \n",
    "In the Fourier spectrum, select in azimuth (vertical positions in the spectrum) a sub-window called sub-aperture, then do zero-padding for the remaining part of the spectrum and compute the inverse Fourier transform. \n",
    "\n",
    "To understand the effects of sub-aperture decomposition, select a sub-aperture and synthesize different images for different selected bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K4UEpwQ-aXo"
   },
   "outputs": [],
   "source": [
    "# sub-aperture using the spectrum of the synthesized image - PARIS\n",
    "\n",
    "mvalab.visusarspectre(image_slc_paris,'original image')\n",
    "imafft=np.fft.fftshift(np.fft.fft2(image_slc_paris))\n",
    "nlin = data_paris[1]\n",
    "ncol = data_paris[2]\n",
    "\n",
    "#take some values for the selected frequencies and study some specific strong targets \n",
    "f1 = 1500\n",
    "df = 500\n",
    "ima_subband_fft=np.zeros((nlin,ncol),dtype=complex)\n",
    "ima_subband_fft[f1:f1+df,:] = ... # COMPLETE \n",
    "\n",
    "ima_subband=np.fft.ifft2(np.fft.fftshift(ima_subband_fft))\n",
    "mvalab.visusarspectre(ima_subband,'sub-aperture filtered image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Lnomz5YApmE"
   },
   "source": [
    "### Bonus: Question 3.a\n",
    "Choose different values for $f_1$ and $d_f$. Comment the images you see: what is the influence of these parameters on the type of reflection you see and on the resolution? \n",
    "\n",
    "Observe some bright scatterers and see how they vary in the different sub-parture selections. How can you explain the variations of the backscattered signals for the different sub-apertures ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpmTeDx3H9Zz"
   },
   "source": [
    "### Bonus: Answer 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f60Z_80ICG5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP1_SAR_synthesis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
